{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable progress bars (requires restarting jupyter lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from zipfile import ZipFile\n",
    "import requests as rq\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "today = date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "sonar = '../sonar.ogg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Download pipeline system data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_2010_present = rq.get('https://www.phmsa.dot.gov/sites/phmsa.dot.gov/files/data_statistics/pipeline/annual_hazardous_liquid_2010_present.zip')\n",
    "pipelines_2004_2009 = rq.get('https://www.phmsa.dot.gov/sites/phmsa.dot.gov/files/data_statistics/pipeline/annual_hazardous_liquid_2004_2009.zip')\n",
    "\n",
    "pipelines_2010_present = ZipFile(io.BytesIO(pipelines_2010_present.content))\n",
    "pipelines_2004_2009 = ZipFile(io.BytesIO(pipelines_2004_2009.content))\n",
    "\n",
    "pipelines_2010_present.extractall(f'../data/pipelines_2010_present_{today}')\n",
    "pipelines_2004_2009.extractall(f'../data/pipelines_2004_2009_{today}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_2010_present = pd.read_excel('../data/pipelines_2010_present_2019-08-09/annual_hazardous_liquid_2010.xlsx', header=2)\n",
    "\n",
    "pipelines_2010_present.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_2010_present = rq.get('https://www.phmsa.dot.gov/sites/phmsa.dot.gov/files/data_statistics/pipeline/annual_liquefied_natural_gas_2010_present.zip')\n",
    "gas_2001_2009 = rq.get('https://www.phmsa.dot.gov/sites/phmsa.dot.gov/files/data_statistics/pipeline/annual_gas_transmission_gathering_2001_2009.zip')\n",
    "\n",
    "gas_2010_present = ZipFile(io.BytesIO(gas_2010_present.content))\n",
    "gas_2001_2009 = ZipFile(io.BytesIO(gas_2001_2009.content))\n",
    "\n",
    "gas_2010_present.extractall(f'../data/gas_2010_present_{today}')\n",
    "gas_2001_2009.extractall(f'../data/gas_2001_2009_{today}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_2010_present = pd.read_excel('../data/gas_2010_present_2019-08-09/annual_liquefied_natural_gas_2015.xlsx', header=2)\n",
    "\n",
    "gas_2010_present.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Download incidents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_file = rq.get('https://www.phmsa.dot.gov/sites/phmsa.dot.gov/files/data_statistics/pipeline/PHMSA_Pipeline_Safety_Flagged_Incidents.zip')\n",
    "incidents_file = ZipFile(io.BytesIO(incidents_file.content))\n",
    "\n",
    "incidents_file.extractall(f'../data/incidents_{today}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_excel('../data/incidents_2019-08-01/hl2010toPresent.xlsx', sheet_name=1)\n",
    "\n",
    "incidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Download FERC notices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download list of all notices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = 'https://www.federalregister.gov/api/v1/documents.json'\n",
    "\n",
    "params = {'fields[]': ['document_number', 'publication_date', 'title', 'raw_text_url'], \n",
    "          'per_page': 1000, \n",
    "          'order': 'oldest', \n",
    "          'conditions[agencies][]': 'federal-energy-regulatory-commission', \n",
    "          'conditions[type][]': 'NOTICE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all pages of one search (for one year) and download data on all documents (before downloading the full-text of all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "\n",
    "def get_documents(api, params, year):\n",
    "    params['conditions[publication_date][year]'] = year\n",
    "    max_page = 9999\n",
    "    page = 1\n",
    "    notices = []\n",
    "    while page <= max_page:\n",
    "        params['page'] = page\n",
    "        with rq.get(api, params=params) as response:\n",
    "            overview = response.json()\n",
    "\n",
    "            max_page = overview['total_pages']\n",
    "            print(f'Loaded year {year}, page {page} of {max_page}.')\n",
    "\n",
    "            results = overview['results']\n",
    "            notices = notices + results\n",
    "        \n",
    "        page += 1\n",
    "        \n",
    "    return notices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all data from 2005-2019, except full-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notices = []\n",
    "for year in range(2005, 2020):\n",
    "    notices = notices + get_documents(api=api, params=params, year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "notices = pd.DataFrame(notices)\n",
    "\n",
    "notices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralellize download of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "from requests import Session\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def download_site(url):\n",
    "    with session.get(url) as response:\n",
    "        return response.text\n",
    "    \n",
    "def download_all_sites(sites, preprocessing=None, processes=8):\n",
    "    with Pool(processes=processes) as pool:\n",
    "        results = tqdm(pool.imap(download_site, sites), total=len(sites))\n",
    "        if preprocessing:\n",
    "            results = map(preprocessing, results)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need this function to clean the individual documents we download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_notice(notice):\n",
    "    return re.findall('<pre>(.*)</pre>', notice, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "notices['full-text'] = download_all_sites(list(notices['raw_text_url']), preprocessing=clean_notice, processes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sonar, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notices.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notices.to_csv(f'../data/ferc_notices_{today}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oil_industry",
   "language": "python",
   "name": "oil_industry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
